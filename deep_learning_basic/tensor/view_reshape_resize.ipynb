{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1、review\n",
    "\n",
    "### 1） 当 tensor 连续时"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "True\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "140203173773632\n",
      "140203173773632\n",
      "(1,)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "b = a.view(2, 3)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.is_contiguous())\n",
    "\n",
    "# 查看结果，会发现二者输出一致，表示存储区的数据并没有发生改变\n",
    "print(a.storage())\n",
    "print(b.storage())\n",
    "\n",
    "# 查看结果，会发现二者输出一致，表示 a 和 b 共享存储区\n",
    "print(a.storage().data_ptr())\n",
    "print(b.storage().data_ptr())\n",
    "\n",
    "# 查看结果，会发现二者在元数据 (metadata) 中的 stride 信息发生了改变\n",
    "print(a.stride())\n",
    "print(b.stride())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T14:35:56.200124Z",
     "end_time": "2024-03-25T14:35:56.205537Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2） 当 tensor 不连续时\n",
    "不连续的 tensor 是不能使用 torch.view() 方法的，否则会报错"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(b)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(b\u001B[38;5;241m.\u001B[39mis_contiguous())\n\u001B[0;32m---> 10\u001B[0m c \u001B[38;5;241m=\u001B[39m \u001B[43mb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(c)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6]).view(2, 3)\n",
    "b = a.t()\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.is_contiguous())\n",
    "\n",
    "c = b.view(6, 1)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T12:07:11.458242Z",
     "end_time": "2024-03-25T12:07:11.467823Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果一定要用 torch.view() 方法，就必须先使用 .contiguous() 方法，让 tensor 先变得连续（重新开辟一块内存空间，生成一个新的、连续的张量对象），再使用 .view() 方法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[1],\n",
      "        [4],\n",
      "        [2],\n",
      "        [5],\n",
      "        [3],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6]).view(2, 3)\n",
    "b = a.t()\n",
    "\n",
    "b = b.contiguous()\n",
    "print(b.is_contiguous())\n",
    "\n",
    "c = b.view(6, 1)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T13:00:26.055162Z",
     "end_time": "2024-03-25T13:00:26.061429Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2、tensor.reshape()\n",
    "\n",
    "### 1）当 tensor 连续时\n",
    "当 tensor 连续时，  tensor.reshape() 与  tensor.view() 效果一样，会和原来 tensor 共用存储区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "True\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6]).view(2, 3)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.is_contiguous())\n",
    "\n",
    "c = b.view(6, 1)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T13:56:39.842506Z",
     "end_time": "2024-03-25T13:56:39.848769Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2）当 tensor 不连续时， reshape() = contiguous() + view()，会先通过产生新的存储区的 tensor，与原来 tensor 不共用存储区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "False\n",
      "tensor([[1],\n",
      "        [4],\n",
      "        [2],\n",
      "        [5],\n",
      "        [3],\n",
      "        [6]])\n",
      "140203159189120\n",
      "140203170387328\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6]).view(2, 3)\n",
    "b = a.t()\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.is_contiguous())\n",
    "\n",
    "c = b.reshape(6, 1)\n",
    "print(c)\n",
    "\n",
    "# 查看结果，会发现二者输出不一致，表示 a 和 b 不共享存储区\n",
    "print(b.storage().data_ptr())\n",
    "print(c.storage().data_ptr())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T14:37:44.651511Z",
     "end_time": "2024-03-25T14:37:44.661078Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3、tensor.resize()\n",
    "\n",
    "### 1）当原始数据 元素多余的时候\n",
    "由以下代码，我们可以观察到，存储区的地址始终都没有改变。a的原始数据始终是 1～7，tensor a 只取了前6个"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140203173778560\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 7]\n",
      "140203173778560\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(a.storage().data_ptr())\n",
    "\n",
    "a = a.resize_(2, 3)\n",
    "print(a)\n",
    "print(a.storage())\n",
    "print(a.storage().data_ptr())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T14:58:31.609040Z",
     "end_time": "2024-03-25T14:58:31.614917Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2）当原始数据 元素不够的时候\n",
    "如果原始数据不够，它会开辟一个新的存储区，并用0进行填充，凑满你要的尺寸"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140203159189120\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 0]])\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 0\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "140203170383296\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(a.storage().data_ptr())\n",
    "\n",
    "a = a.resize_(2, 3)\n",
    "print(a)\n",
    "print(a.storage())\n",
    "print(a.storage().data_ptr())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-25T14:59:07.344086Z",
     "end_time": "2024-03-25T14:59:07.363568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
