{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1、参数 key_padding_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        [[False, False, False],\n",
      "         [False, False, False],\n",
      "         [ True,  True,  True]]])\n",
      "torch.Size([2, 9, 3])\n",
      "torch.Size([2, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image1 = torch.rand(3, 3, 2)  # c, h, w\n",
    "image2 = torch.rand(3, 2, 3)  # c, h, w\n",
    "max_size = [max(n1, n2) for n1, n2 in zip(image1.shape, image2.shape)]\n",
    "\n",
    "batch_shape = [2] + max_size\n",
    "b, c, h, w = batch_shape\n",
    "\n",
    "batch_image = torch.zeros(batch_shape)\n",
    "key_padding_mask = torch.full((b, h, w), True, dtype=torch.bool)\n",
    "\n",
    "batch_image[0, :image1.shape[0], :image1.shape[1], :image1.shape[2]] = image1\n",
    "key_padding_mask[0, :image1.shape[1], :image1.shape[2]] = False\n",
    "\n",
    "batch_image[1, :image2.shape[0], :image2.shape[1], :image2.shape[2]] = image2\n",
    "key_padding_mask[1, :image2.shape[1], :image2.shape[2]] = False\n",
    "print(key_padding_mask)\n",
    "\n",
    "batch_image = batch_image.flatten(-2).permute(0, 2, 1)\n",
    "key_padding_mask = key_padding_mask.flatten(-2)\n",
    "\n",
    "\n",
    "q = k = v = batch_image\n",
    "self_attn = nn.MultiheadAttention(embed_dim=3, num_heads=1, batch_first=True)\n",
    "attn_output, attn_output_weights = self_attn(q, k, v, key_padding_mask=key_padding_mask)\n",
    "\n",
    "print(attn_output.shape)   # torch.Size([2, 9, 3])\n",
    "print(attn_output_weights.shape)   # torch.Size([2, 9, 9])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2、参数 att_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False]])\n",
      "torch.Size([2, 4, 3])\n",
      "torch.Size([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "tgt = torch.rand(2, 4, 3)  # b, len_q, embed_dim\n",
    "memory = torch.rand(2, 5, 3)  # b, len_k, embed_dim\n",
    "\n",
    "b, len_q, _ = tgt.shape\n",
    "_, len_k, _ = memory.shape\n",
    "\n",
    "attn_mask = torch.full([len_q, len_k], False, dtype=torch.bool)\n",
    "attn_mask[1:, :2] = True\n",
    "print(attn_mask)\n",
    "\n",
    "self_attn = nn.MultiheadAttention(embed_dim=3, num_heads=1, batch_first=True)\n",
    "attn_output, attn_output_weights = self_attn(tgt, memory, memory, attn_mask=attn_mask)\n",
    "\n",
    "print(attn_output.shape)\n",
    "print(attn_output_weights.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3、key_padding_mask 和 attn_mask 可以等效使用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1327, -0.3230, -0.0430],\n",
      "        [-0.1277, -0.3282, -0.0476],\n",
      "        [-0.1281, -0.3278, -0.0473]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[-0.1327, -0.3230, -0.0430],\n",
      "        [-0.1277, -0.3282, -0.0476],\n",
      "        [-0.1281, -0.3278, -0.0473]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[0.5110, 0.4890, 0.0000],\n",
      "        [0.4933, 0.5067, 0.0000],\n",
      "        [0.4947, 0.5053, 0.0000]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[0.5110, 0.4890, 0.0000],\n",
      "        [0.4933, 0.5067, 0.0000],\n",
      "        [0.4947, 0.5053, 0.0000]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "q = k = v = torch.rand(3, 3)\n",
    "key_padding_mask = torch.tensor([False, False, True], dtype=torch.bool)\n",
    "attn_mask = torch.tensor([[False, False, True], [False, False, True], [False, False, True]], dtype=torch.bool)\n",
    "\n",
    "self_attn = nn.MultiheadAttention(embed_dim=3, num_heads=1, batch_first=True)\n",
    "attn_output1, attn_output_weights1 = self_attn(q, k, v, key_padding_mask=key_padding_mask)\n",
    "attn_output2, attn_output_weights2 = self_attn(q, k, v, attn_mask=attn_mask)\n",
    "print(attn_output1)\n",
    "print(attn_output2)\n",
    "print(attn_output_weights1)\n",
    "print(attn_output_weights2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-16T18:42:43.181626Z",
     "end_time": "2024-03-16T18:42:43.188528Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4、小实验"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0569, -0.0939, -0.0323],\n",
      "         [-0.0557, -0.0919, -0.0316],\n",
      "         [-0.0530, -0.0872, -0.0294],\n",
      "         [-0.0560, -0.0924, -0.0320],\n",
      "         [-0.0599, -0.0992, -0.0350],\n",
      "         [-0.0530, -0.0872, -0.0294],\n",
      "         [-0.0581, -0.0960, -0.0337],\n",
      "         [-0.0577, -0.0955, -0.0335],\n",
      "         [-0.0530, -0.0872, -0.0294]],\n",
      "\n",
      "        [[-0.0552, -0.0888, -0.0238],\n",
      "         [-0.0625, -0.1012, -0.0288],\n",
      "         [-0.0648, -0.1051, -0.0301],\n",
      "         [-0.0594, -0.0959, -0.0266],\n",
      "         [-0.0618, -0.1001, -0.0285],\n",
      "         [-0.0596, -0.0963, -0.0268],\n",
      "         [-0.0554, -0.0891, -0.0238],\n",
      "         [-0.0554, -0.0891, -0.0238],\n",
      "         [-0.0554, -0.0891, -0.0238]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([2, 9, 3])\n",
      "torch.Size([2, 9, 9])\n",
      "[{'in_proj_weight': torch.Size([9, 3])}, {'in_proj_bias': torch.Size([9])}, {'out_proj.weight': torch.Size([3, 3])}, {'out_proj.bias': torch.Size([3])}]\n",
      "tensor([[[-0.0569, -0.0939, -0.0323],\n",
      "         [-0.0557, -0.0919, -0.0316],\n",
      "         [-0.0530, -0.0872, -0.0294],\n",
      "         [-0.0560, -0.0924, -0.0320],\n",
      "         [-0.0599, -0.0992, -0.0350],\n",
      "         [-0.0530, -0.0872, -0.0294],\n",
      "         [-0.0581, -0.0960, -0.0337],\n",
      "         [-0.0577, -0.0955, -0.0335],\n",
      "         [-0.0530, -0.0872, -0.0294]],\n",
      "\n",
      "        [[-0.0552, -0.0888, -0.0238],\n",
      "         [-0.0625, -0.1012, -0.0288],\n",
      "         [-0.0648, -0.1051, -0.0301],\n",
      "         [-0.0594, -0.0959, -0.0266],\n",
      "         [-0.0618, -0.1001, -0.0285],\n",
      "         [-0.0596, -0.0963, -0.0268],\n",
      "         [-0.0554, -0.0891, -0.0238],\n",
      "         [-0.0554, -0.0891, -0.0238],\n",
      "         [-0.0554, -0.0891, -0.0238]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image1 = torch.rand(3, 3, 2)  # c, h, w\n",
    "image2 = torch.rand(3, 2, 3)  # c, h, w\n",
    "max_size = [max(n1, n2) for n1, n2 in zip(image1.shape, image2.shape)]\n",
    "\n",
    "batch_shape = [2] + max_size\n",
    "b, c, h, w = batch_shape\n",
    "\n",
    "batch_image = torch.zeros(batch_shape)\n",
    "padding_mask = torch.ones((b, h, w))\n",
    "\n",
    "batch_image[0, :image1.shape[0], :image1.shape[1], :image1.shape[2]] = image1\n",
    "padding_mask[0, :image1.shape[1], :image1.shape[2]] = False\n",
    "\n",
    "batch_image[1, :image2.shape[0], :image2.shape[1], :image2.shape[2]] = image2\n",
    "padding_mask[1, :image2.shape[1], :image2.shape[2]] = False\n",
    "\n",
    "batch_image = batch_image.flatten(-2).permute(0, 2, 1)\n",
    "padding_mask = padding_mask.flatten(-2)\n",
    "q = k = v = batch_image\n",
    "\n",
    "self_attn = nn.MultiheadAttention(embed_dim=3, num_heads=1, batch_first=True)\n",
    "attn_output, attn_output_weights = self_attn(q, k, v, key_padding_mask=padding_mask)\n",
    "\n",
    "print(attn_output)\n",
    "print(attn_output.shape)   # torch.Size([2, 9, 3])\n",
    "print(attn_output_weights.shape)   # torch.Size([2, 9, 9])\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "parm_info = [{param_name:param.shape} for param_name, param in self_attn.named_parameters()]\n",
    "print(parm_info)\n",
    "\n",
    "input_linear = nn.Linear(3, 3)\n",
    "input_linear.weight = nn.Parameter(self_attn.in_proj_weight[6:, :])\n",
    "input_linear.bias = nn.Parameter(self_attn.in_proj_bias[6:])\n",
    "v = v.contiguous().view(b*h*w, c)\n",
    "v = input_linear(v).view(b, h*w, c)\n",
    "\n",
    "o = torch.bmm(attn_output_weights, v)\n",
    "o = o.contiguous().view(b*h*w, c)\n",
    "\n",
    "output_linear = nn.Linear(3, 3)\n",
    "output_linear.weight = self_attn.out_proj.weight\n",
    "output_linear.bias = self_attn.out_proj.bias\n",
    "o = output_linear(o)\n",
    "\n",
    "o = o.view(b, h*w, c)\n",
    "print(o)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-16T18:49:55.266073Z",
     "end_time": "2024-03-16T18:49:55.273027Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
